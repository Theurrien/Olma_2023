[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Deskriptive Statistik",
    "section": "",
    "text": "Code\nlibrary(survey)\nlibrary(tidyverse)\nlibrary(haven)\nlibrary(ggplot2)\nlibrary(knitr)\nlibrary(gt)\nlibrary(lavaan)\nlibrary(psych)\nlibrary(GPArotation)\n\n\n# Working directory\nsetwd(\"~/Library/Mobile Documents/com~apple~CloudDocs/R_Studio/Olma_2023/Olma_2023\")\n\n\n# Import data\n\nOLMA_Start &lt;- read_sav(\"data_project.sav\")\n\n# Data Prep\nOLMA_Ready &lt;- OLMA_Start %&gt;% \n  mutate(Bildung = haven::as_factor(Bildung),\n         Bildung = case_when(\n           Bildung == \"Berufsbildung (EBA/EFZ)\" ~ \"Berufsbildung\",\n           Bildung == \"Hochschule (Universität, ETH, Fachhochschule)\" ~ \"Hochschule\",\n           Bildung == \"höhere Berufsbildung (Berufs- und höhere Fachprüfung, höhere Fachschule)\" ~ \"höhere Berufsbildung\",\n           Bildung == \"obligatorische Schule\" ~ \"Volksschule\",\n           Bildung == \"Ich habe kein Bildungsabschluss\" ~ \"Ohne\",\n           Bildung == \"Andere\" ~ \"Volksschule\",\n           Bildung == 0 ~ \"Volksschule\",\n           TRUE ~ as.character(Bildung)\n         ),\n         Bildung = factor(Bildung, levels = c(\"Ohne\", \"Volksschule\", \"Gymnasium/Fachmittelschule\", \"Berufsbildung\", \"höhere Berufsbildung\", \"Hochschule\", ordered=TRUE))) %&gt;% \n  mutate(\n    WIS_1=if_else(WIS_1==3,1,0),\n    WIS_2=if_else(WIS_2==1,1,0),\n    WIS_3=if_else(WIS_3==4,1,0),\n    Antworten=WIS_1+WIS_2+WIS_3,\n    Antworten = factor(Antworten, levels=c(0,1,2,3), ordered=TRUE)\n  ) %&gt;% \n  mutate(\n    CANX_1=8-CANX_1,\n    IMO_3=6-IMO_3,\n    IMO_4=6-IMO_4,\n    Alter = as.numeric(Alter)\n    ) %&gt;% \n  select(-c(1:7,40:79))"
  },
  {
    "objectID": "index.html#demographische-angaben",
    "href": "index.html#demographische-angaben",
    "title": "Deskriptive Statistik",
    "section": "Demographische Angaben",
    "text": "Demographische Angaben\nIn diesem Datensatz haben bislang 554 Personen teilgennommen.\n\nAlter\nDie Angabe des Alters wurde in ganzen Jahren erfasst Abbildung 1\n\n\nCode\n# Calculate the count for each bin\nbins &lt;- cut(OLMA_Start$Alter, breaks = seq(min(OLMA_Start$Alter, na.rm = TRUE), \n                                           max(OLMA_Start$Alter, na.rm = TRUE), by = 10), include.lowest = TRUE)\nbin_counts &lt;- as.numeric(table(bins))\n\n# Find the maximum height of the bins\nmax_count &lt;- max(bin_counts)\n\n# First, calculate the mean and median outside of the ggplot2 calls\nalter_mean &lt;- mean(OLMA_Start$Alter, na.rm = TRUE)\nalter_median &lt;- median(OLMA_Start$Alter, na.rm = TRUE)\n\nOLMA_Start %&gt;%\n  ggplot() +\n  geom_histogram(aes(Alter), binwidth = 5) +\n  geom_vline(aes(xintercept = alter_mean), color = \"red\", linetype = \"dashed\") +\n  geom_vline(aes(xintercept = alter_median), color = \"red\", linetype = \"dashed\")+\n  geom_text(aes(x = alter_mean, y = max_count, \n                label = sprintf(\"Mw\")),\n            color = \"black\", check_overlap = TRUE,  hjust=-0.2) +\n  geom_text(aes(x = alter_median, y = max_count, \n                label = sprintf(\"M\")),\n            color = \"black\", check_overlap = TRUE,  hjust=-0.2)+\n  labs(\n    title = \"Altersverteilung\",\n    subtitle = \"mit Mittelwert (Mw) und Median (M)\",\n    caption = paste(sprintf(\"Mittelwert: %.2f;\", alter_mean), sprintf(\"Median: %.2f\", alter_median))\n  )+\n  ylab(\"Anzahl\")+\n  theme_minimal()\n\n\n\n\n\nAbbildung 1: Verteilung der Altersangaben\n\n\n\n\n\n\nBildungsabschluss\nDie erreichten Bildungsabschlüsse verteilen sich wie in Tabelle 1 dargestellt.\n\n\nCode\nOLMA_Ready %&gt;%\n  group_by(Bildung) %&gt;%\n  summarise(Anzahl = n(),\n            'Mw Alter' = round(mean(Alter),1),\n            'SD Alter' = round(sd(Alter),1)\n            ) %&gt;%\n  mutate('%'=round(Anzahl/sum(Anzahl)*100,2)) %&gt;% \n  select(Bildung, Anzahl, '%', 'Mw Alter', 'SD Alter') %&gt;% \n gt() %&gt;% \n  tab_style(\n    style = cell_text(\n      align = \"left\"),\n    locations = cells_body(\n      columns=Bildung\n    )) %&gt;% \n  tab_style(\n    style = cell_text(align = \"left\"),\n    locations = cells_column_labels(columns=Bildung)\n  )\n\n\n\n\n\n\n\n  \n    \n    \n      Bildung\n      Anzahl\n      %\n      Mw Alter\n      SD Alter\n    \n  \n  \n    Ohne\n17\n3.07\n17.8\n18.2\n    Volksschule\n50\n9.03\n26.4\n19.5\n    Gymnasium/Fachmittelschule\n31\n5.60\n41.4\n22.1\n    Berufsbildung\n139\n25.09\n47.4\n17.3\n    höhere Berufsbildung\n155\n27.98\n47.9\n15.6\n    Hochschule\n162\n29.24\n45.9\n16.0\n  \n  \n  \n\nTabelle 1:  Übersicht der Bildungsabschlüsse"
  },
  {
    "objectID": "index.html#vorwissen-mit-vr",
    "href": "index.html#vorwissen-mit-vr",
    "title": "Deskriptive Statistik",
    "section": "Vorwissen mit VR",
    "text": "Vorwissen mit VR\nDas Vorwissen umfasst die Häufigkeit mit welcher die Personen bereits Erfahrungen mit VR Endgeräten gesammelt haben (vgl. Abbildung 2). Bei vorhandenen Erfahrungen wurde weiter erfragt woher diese stammen (vgl Tabelle 2)\n\n\nCode\nOLMA_Start %&gt;%\n  mutate(VoWi_Count = haven::as_factor(VoWi_Count)) %&gt;%\n  select(VoWi_Count) %&gt;%\n  ggplot() +\n  geom_bar(aes(VoWi_Count))+\n  labs(\n    title = \"Angaben über Vorwissen in VR\"\n  )+\n  ylab(\"Anzahl\")+\n  xlab(\"\")+\n  theme_minimal()\n\n\n\n\n\nAbbildung 2: Angaben über die Benutzungshäufigkeit von VR Devices\n\n\n\n\n\nAnwendung der VR Technologie\nMenschen, die bereits einige Vorerfahrung mit VR angaben, wurden gebeten, das Anwendungsfeld zu bezeichnen. Die folgende Tabelle zeigt nur Mehrfachnennungen.\n\n\nCode\nOLMA_Start %&gt;% \n  select(starts_with(\"VoWi\")) %&gt;% \n  filter(VoWi_Anlass != -99,\n         VoWi_Count !=1) %&gt;% \n  mutate(Aussage=str_to_lower(VoWi_Anlass),\n         Kategorie=haven::as_factor(VoWi_Count)) %&gt;% \n   group_by(Kategorie, Aussage) %&gt;%   # Group by both category and word\n  tally() %&gt;%                         # Count occurrences\n  arrange(Kategorie, desc(n)) %&gt;% \n  filter(n&gt;1) %&gt;% \n  gt() %&gt;% \n    tab_style(\n    style = list(\n      cell_fill(color = \"bisque\"),\n      cell_text(weight = \"bold\")),\n    locations = cells_row_groups(groups = c(1,2))\n  ) %&gt;% \n  cols_width(\n    everything() ~ pct(50)\n  ) |&gt; \n  cols_align(\n    align = \"center\",\n    columns = n\n  )  %&gt;% \n  cols_align(\n    align = \"auto\",\n    columns = Aussage\n  )\n\n\n\n\n\n\n\n  \n    \n    \n  \n  \n    \n    \n      Aussage\n      n\n    \n  \n  \n    \n      1 Mal\n    \n    olma\n14\n    freizeit\n4\n    ausstellung\n3\n    ausprobieren\n2\n    europapark\n2\n    hier an der olma\n2\n    kino\n2\n    messe\n2\n    spass\n2\n    \n      2 - 10 Mal\n    \n    freizeit\n9\n    arbeit\n4\n    gaming\n4\n    messe\n4\n    an messen\n3\n    ausstellungen\n3\n    gamen\n3\n    messen\n3\n    europapark\n2\n    im verkehrshaus\n2\n    olma\n2\n    schule\n2\n    spiel\n2\n    spiele\n2\n    weiterbildung\n2\n  \n  \n  \n\nTabelle 2:  Nennungen der Anwendungsorte"
  },
  {
    "objectID": "index.html#skalenüberischt",
    "href": "index.html#skalenüberischt",
    "title": "Deskriptive Statistik",
    "section": "Skalenüberischt",
    "text": "Skalenüberischt\nDie Angst oder Furcht vor Computern wurde mit der Computer Anxiety Scale1 erfasst.\n\nÜbersichtReliabilität - TabelleRelibilität - Visualisierung\n\n\n\n\nCode\nOLMA_Items &lt;- OLMA_Start %&gt;% \n  select(dplyr::starts_with(c(\"CAN\", \"PRA\", \"IMO\", \"KBE\", \"KBU\"))) %&gt;% \n  mutate(\n    CANX_1=8-CANX_1,\n    IMO_3=6-IMO_3,\n    IMO_4=6-IMO_4\n    )\n\nScale_Names &lt;- c(\n  CAN = \"Computer Ängstlichkeit\",\n  PRA = \"Präsenz\",\n  IMO = \"Intrinsische Motivation\",\n  KBE = \"Kognitive Belastung durch externe Faktoren\",\n  KBU = \"Kognitive Belastung durch die Umgebung\"\n)\n\nOLMA_Items %&gt;% \n  describe() %&gt;% \n  as.data.frame() %&gt;% \n  mutate(Variable = rownames(.)) %&gt;% \n  select(Variable, dplyr::everything()) %&gt;% \n  select(-vars, -n, -trimmed, -mad) %&gt;% \n  mutate(Scale = substr(Variable, 1, 3)) %&gt;% \n  mutate(Scale = Scale_Names[Scale]) %&gt;% \n  group_by(Scale) %&gt;% \n  gt() %&gt;% \n  fmt_number() %&gt;% \n  tab_style(\n      style = list(\n      cell_fill(color = \"bisque\"),\n      cell_text(weight = \"bold\")),\n      locations = cells_row_groups(groups = c(1,2,3,4,5)))\n\n\n\n\n\n\n\n  \n    \n    \n      Variable\n      mean\n      sd\n      median\n      min\n      max\n      range\n      skew\n      kurtosis\n      se\n    \n  \n  \n    \n      Computer Ängstlichkeit\n    \n    CANX_1\n2.51\n1.83\n2.00\n1.00\n7.00\n6.00\n1.21\n0.32\n0.08\n    CANX_2\n2.34\n1.74\n2.00\n1.00\n7.00\n6.00\n1.27\n0.43\n0.07\n    CANX_3\n2.23\n1.65\n2.00\n1.00\n7.00\n6.00\n1.39\n0.86\n0.07\n    CANX_4\n2.06\n1.48\n1.00\n1.00\n7.00\n6.00\n1.58\n1.81\n0.06\n    \n      Präsenz\n    \n    PRA_1\n3.77\n0.92\n4.00\n1.00\n5.00\n4.00\n−0.88\n0.64\n0.04\n    PRA_2\n2.87\n1.11\n3.00\n1.00\n5.00\n4.00\n0.00\n−0.99\n0.05\n    PRA_3\n3.50\n1.02\n4.00\n1.00\n5.00\n4.00\n−0.55\n−0.55\n0.04\n    PRA_4\n3.74\n1.06\n4.00\n1.00\n5.00\n4.00\n−0.74\n−0.19\n0.05\n    \n      Intrinsische Motivation\n    \n    IMO_1\n3.57\n1.12\n4.00\n1.00\n5.00\n4.00\n−0.43\n−0.55\n0.05\n    IMO_2\n3.96\n0.95\n4.00\n1.00\n5.00\n4.00\n−0.87\n0.49\n0.04\n    IMO_3\n4.30\n0.88\n5.00\n1.00\n5.00\n4.00\n−1.40\n2.13\n0.04\n    IMO_4\n4.21\n1.01\n5.00\n1.00\n5.00\n4.00\n−1.29\n1.04\n0.04\n    IMO_5\n3.81\n1.14\n4.00\n1.00\n5.00\n4.00\n−0.94\n0.16\n0.05\n    \n      Kognitive Belastung durch externe Faktoren\n    \n    KBE_1\n1.59\n0.88\n1.00\n1.00\n5.00\n4.00\n1.86\n3.73\n0.04\n    KBE_2\n2.25\n1.28\n2.00\n1.00\n5.00\n4.00\n0.69\n−0.74\n0.05\n    KBE_3\n1.76\n0.92\n2.00\n1.00\n5.00\n4.00\n1.31\n1.56\n0.04\n    KBE_4\n1.47\n0.76\n1.00\n1.00\n5.00\n4.00\n1.83\n3.56\n0.03\n    \n      Kognitive Belastung durch die Umgebung\n    \n    KBU_1\n1.59\n0.76\n1.00\n1.00\n5.00\n4.00\n1.42\n2.37\n0.03\n    KBU_2\n1.89\n1.09\n2.00\n1.00\n5.00\n4.00\n1.27\n0.86\n0.05\n    KBU_3\n1.71\n0.90\n1.00\n1.00\n5.00\n4.00\n1.36\n1.59\n0.04\n    KBU_4\n1.59\n0.81\n1.00\n1.00\n5.00\n4.00\n1.59\n2.73\n0.03\n  \n  \n  \n\nTabelle 3:  Item Statistik \n\n\n\n\n\n\n\nCode\nitem.list&lt;-list(\n  CANX = c(\"CANX_1\",\"CANX_2\", \"CANX_3\", \"CANX_4\"),\n  PRA = c(\"PRA_1\", \"PRA_2\", \"PRA_3\", \"PRA_4\"),\n  IMO = c(\"IMO_1\", \"IMO_2\", \"IMO_3\", \"IMO_4\", \"IMO_5\"),\n  KBE = c(\"KBE_1\", \"KBE_2\", \"KBE_3\", \"KBE_4\"),\n  KBU = c(\"KBU_1\", \"KBU_2\", \"KBU_3\", \"KBU_4\")\n)\n\nrel_items &lt;-reliability(keys = item.list, OLMA_Items)\n\nrel_items$result.df %&gt;% \n  as.data.frame() %&gt;% \n  mutate(Variable=rownames(rel_items$result.d)) %&gt;% \n  select(Variable, dplyr::everything()) %&gt;% \n  select(-omega_h, -min.split, -cong) %&gt;% \n  gt() %&gt;% \n  fmt_number() %&gt;% \n  fmt_number(columns = n.items, decimals = 0) \n\n\n\n\n\n\n  \n    \n    \n      Variable\n      alpha\n      omega.tot\n      Uni\n      tau\n      max.split\n      mean.r\n      med.r\n      n.items\n    \n  \n  \n    CANX\n0.71\n0.77\n0.72\n0.72\n0.74\n0.38\n0.36\n4\n    PRA\n0.75\n0.76\n0.99\n0.99\n0.76\n0.42\n0.42\n4\n    IMO\n0.78\n0.85\n0.88\n0.91\n0.82\n0.42\n0.42\n5\n    KBE\n0.69\n0.76\n0.90\n0.92\n0.76\n0.36\n0.35\n4\n    KBU\n0.77\n0.84\n0.96\n0.97\n0.83\n0.46\n0.46\n4\n  \n  \n  \n\n\n\n\n\n\n\n\nCode\nplot(rel_items)"
  },
  {
    "objectID": "index.html#wissensfragen",
    "href": "index.html#wissensfragen",
    "title": "Deskriptive Statistik",
    "section": "Wissensfragen",
    "text": "Wissensfragen\nDas Lernen in der VR sImulation wurde durch drei MC-Fragen operationalisiert.\n\n\nCode\nOLMA_Ready %&gt;% \n   select(dplyr::starts_with(\"WIS\"), Antworten) %&gt;% \n  group_by(Antworten) %&gt;% \n  summarise(Anzahl=n()) %&gt;% \n  mutate('%'=round(Anzahl/sum(Anzahl)*100,2)) %&gt;% \n  gt()\n\n\n\n\n\n\n  \n    \n    \n      Antworten\n      Anzahl\n      %\n    \n  \n  \n    0\n19\n3.43\n    1\n76\n13.72\n    2\n179\n32.31\n    3\n280\n50.54\n  \n  \n  \n\n\n\n\nIn Abhängigkeit von Alter und Bildungsstufe ergibt sich folgendes Bild:\n\n\nCode\nOLMA_Ready %&gt;% \n  ggplot(aes(x=Alter, y=Bildung, color=Antworten))+\n  geom_point(position = \"jitter\")+\n  annotate(\n    'rect',\n    ymax=2.8,\n    xmin=2,\n    ymin=0.5,\n    xmax = 20,\n    alpha=0.25\n  )+\n  annotate(\n    'text',\n    x=50,\n    y=1.2,\n    label=\"Gruppe der Jugendlichen\")\n\n\n\n\n\n\n\nCode\nOLMA_Ready %&gt;% \n  ggplot(aes(x=Alter, y=Antworten))+\n  geom_point(position = \"jitter\")+\n   geom_smooth(aes(group=1), method = 'lm',  color=\"blue\")+\n  facet_wrap(~Bildung)+\n  theme_minimal()+\n  labs(\n    title = \"Lernerfolg nach Bildung und Alter\",\n    subtitle = \"einfache lineare Regression\"\n  )"
  },
  {
    "objectID": "index.html#footnotes",
    "href": "index.html#footnotes",
    "title": "Deskriptive Statistik",
    "section": "Fußnoten",
    "text": "Fußnoten\n\n\nThe degree of “an individual’s apprehension, or even fear, when she/he is faced with the possibility of using computers” [@venkateshDeterminantsPerceivedEase2000, p.349]↩︎"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Statistische Analyse",
    "section": "",
    "text": "Code\nlibrary(tidyverse)\nlibrary(lavaan)\nlibrary(haven)\nlibrary(gt)\nlibrary(lavaanPlot)\nlibrary(performance)\nlibrary(tidySEM)\nlibrary(psych)\nlibrary(semPlot)\nlibrary(corrplot)\n# Import data\n\nOLMA_Start &lt;- read_sav(\"data_project.sav\")\n\n# Data Prep\nOLMA_Ready &lt;- OLMA_Start %&gt;% \n  mutate(Bildung = haven::as_factor(Bildung),\n         Bildung = case_when(\n           Bildung == \"Berufsbildung (EBA/EFZ)\" ~ \"Berufsbildung\",\n           Bildung == \"Hochschule (Universität, ETH, Fachhochschule)\" ~ \"Hochschule\",\n           Bildung == \"höhere Berufsbildung (Berufs- und höhere Fachprüfung, höhere Fachschule)\" ~ \"höhere Berufsbildung\",\n           Bildung == \"obligatorische Schule\" ~ \"Volksschule\",\n           Bildung == \"Ich habe kein Bildungsabschluss\" ~ \"Ohne\",\n           Bildung == \"Andere\" ~ \"Volksschule\",\n           Bildung == 0 ~ \"Volksschule\",\n           TRUE ~ as.character(Bildung)\n         ),\n         Bildung = factor(Bildung, levels = c(\"Ohne\", \"Volksschule\", \"Gymnasium/Fachmittelschule\", \"Berufsbildung\", \"höhere Berufsbildung\", \"Hochschule\", ordered=TRUE))) %&gt;% \n  mutate(\n    WIS_1=if_else(WIS_1==3,1,0),\n    WIS_2=if_else(WIS_2==1,1,0),\n    WIS_3=if_else(WIS_3==4,1,0),\n    WIS_Total=WIS_1+WIS_2+WIS_3,\n    WIS_Total = factor(WIS_Total, levels=c(0,1,2,3), ordered=TRUE)\n  ) %&gt;% \n  mutate(\n    CANX_1=8-CANX_1,\n    IMO_3=6-IMO_3,\n    IMO_4=6-IMO_4,\n    Alter = as.numeric(Alter),\n    ) %&gt;% \n  rowwise() %&gt;% \n  mutate(\n    CANX_mean = mean(c_across(dplyr::starts_with(\"CANX\"))),\n    PRA_mean = mean(c_across(dplyr::starts_with(\"PRA\"))),\n    IMO_mean = mean(c_across(dplyr::starts_with(\"IMO\"))),\n    KBE_mean = mean(c_across(dplyr::starts_with(\"KBE\"))),\n    KBU_mean = mean(c_across(dplyr::starts_with(\"KBU\"))),\n  ) %&gt;% \n  select(-c(1:6, 40:80)) \n#%&gt;% write_sav(\"OLMA_ready_mean.sav\")\n\n#Definition einer Funtion für die Berechnung der Äquivalenzwerte\ncalculate_cutoff &lt;- function(df, N, p) {\n  \n  n &lt;- N - 1\n  df_i &lt;- p * (p - 1) / 2\n  \n  CFI_e99 &lt;- 1 - exp(\n    4.67603 - .50827 * log(df) + .87087 * (df^(1/5)) - .59613 * ((df_i)^(1/5)) - 1.89602 * log(n)\n    + .10190 * ((log(n))^2) + .03729 * log(df) * log(n)\n  )\n  \n  CFI_e95 &lt;- 1 - exp(\n    4.12132 - .46285 * log(df) + .52478 * (df^(1/5)) - .31832 * ((df_i)^(1/5)) - 1.74422 * log(n)\n    + .13042 * ((log(n))^2) - .02360 * (n^(1/2)) + .04215 * log(df) * log(n)\n  )\n  \n  CFI_e92 &lt;- 1 - exp(\n    6.31234 - .41762 * log(df) + .01554 * ((log(df))^2) - .00563 * ((log(df_i))^2) - 1.30229 * log(n)\n    + .19999 * ((log(n))^2) - 2.17429 * (n^(1/5)) + .05342 * log(df) * log(n) - .01520 * log(df_i) * log(n)\n  )\n  \n  CFI_e90 &lt;- 1 - exp(\n    5.96633 - .40425 * log(df) + .01384 * ((log(df))^2) - .00411 * ((log(df_i))^2) - 1.20242 * log(n)\n    + .18763 * ((log(n))^2) - 2.06704 * (n^(1/5)) + .05245 * log(df) * log(n) - .01533 * log(df_i) * log(n)\n  )\n  \n  RMSEA_e01=exp(\n    1.34863-.51999*log(df)+.01925*log(df)*log(df)-.59811*log(n)+.00902*sqrt(n)+.01796*log(df)*log(n)\n  );\n  #corresponding to R-square=.9997;\n  \n  RMSEA_e05=exp(\n    2.06034-.62974*log(df)+.02512*log(df)*log(df)-.98388*log(n)\n    +.05442*log(n)*log(n)-.00005188*n+.05260*log(df)*log(n)\n  );\n  #corresponding to R-square=.9996;\n  \n  RMSEA_e08=exp(\n    2.84129-.54809*log(df)+.02296*log(df)*log(df)-.76005*log(n)\n    +.10229*log(n)*log(n)-1.11167*(n^.2)+.04845*log(df)*log(n)\n  );\n  #corresponding to R-square=.9977;\n  \n  RMSEA_e10=exp(\n    2.36352-.49440*log(df)+.02131*log(df)*log(df)-.64445*log(n)\n    +.09043*log(n)*log(n)-1.01634*(n^.2)+.04422*log(df)*log(n)\n  );\n  #corresponding to R-square=.9955;\n  \n  \n  cutoff_CFI &lt;- as.vector(rbind(CFI_e90, CFI_e92, CFI_e95, CFI_e99))\n  cutoff_RMSEA=as.vector(rbind(RMSEA_e10, RMSEA_e08, RMSEA_e05, RMSEA_e01))\n  \n  # Creating the data frame\n  cutoff_df &lt;- data.frame(CFI = cutoff_CFI, RMSEA = cutoff_RMSEA)\n  rownames(cutoff_df) &lt;- c(\"mediocre\", \"fair\", \"close\", \"excellent\")\n  \n  return(cutoff_df)\n}\n\n#Äquivalenztestwerte\nequivalence_testing &lt;- function(N, p, T_ml, df, T_mli, alpha) {\n  \n  # Calculate ncp_chi2\n  ncp_chi2=function(alpha, T_ml,df){\n  z=qnorm(1-alpha);\n  z2=z*z; z3=z2*z; z4=z3*z; z5=z4*z;\n  sig2=2*(2*T_ml-df+2);\n  sig=sqrt(sig2); sig3=sig*sig2; sig4=sig2*sig2;sig5=sig4*sig;\n  sig6=sig2*sig4;\n  \n  delta=T_ml-df+2+sig*\n    (\n      z+(z2-1)/sig-z/sig2 + 2*(df-1)*(z2-1)/(3*sig3)\n      +( -(df-1)*(4*z3-z)/6+(df-2)*z/2 )/sig4\n      +4*(df-1)*(3*z4+2*z2-11)/(15*sig5)\n      +(\n        -(df-1)*(96*z5+164*z3-767*z)/90-4*(df-1)*(df-2)*(2*z3-5*z)/9\n        +(df-2)*z/2\n      )/sig6\n    );\n  delta=max(delta,0);\n  return(delta)\n}\n  # Calculate df_i\n  df_i = p * (p + 1) / 2 - p\n  \n  # For T-size RMSEA\n  delta_c = max(0, T_ml - df)\n  RMSEA_c = sqrt(delta_c / ((N - 1) * df))\n  \n  delta_t = ncp_chi2(alpha, T_ml, df)\n  RMSEA_t = sqrt(delta_t / (df * (N - 1)))\n  \n  # For T-size CFI\n  delta_i = T_mli - df_i\n  CFI_c = 1 - delta_c / max(delta_c, delta_i, 0)\n  \n  delta_t = ncp_chi2(alpha / 2, T_ml, df)\n  delta_it = ncp_chi2(1 - alpha / 2, T_mli, df_i)\n  CFI_t = 1 - max(delta_t, 0) / max(delta_t, delta_it, 0)\n  \n  # Creating the data frame with results\n  result_df &lt;- data.frame(\n    Method = c(\"Conventional\", \"T-Size\"),\n    CFI = c(CFI_c, CFI_t),\n    RMSEA = c(RMSEA_c, RMSEA_t)\n  )\n  \n  return(result_df)\n}"
  },
  {
    "objectID": "about.html#strukturgleichungsmodell",
    "href": "about.html#strukturgleichungsmodell",
    "title": "Statistische Analyse",
    "section": "",
    "text": "Basierend auf Camil (Makransky and Petersen 2021) und der Annahme, dass das Alter und die Ängstlichkeit vor Computern einen Einfluss auf das Lernen hat, wurde das folgenden Modell aufgestellt.\n\n\n\nDas Messmodell beinhaltet die fünf Skalen:\n\nCANX (Computer Anxiety) - Ängstlichkeit vor Computern\nPRA (Presence) - Präsenz im virtuellen Raum\nIMO (Intrinsic motivation) - Intrinsische Motivation\nKBE (Extraneous Cognitive load Interaction) - Kognitive Belastung, Interaktion\nKBU (Extranous Cognitive load Environment) - Kognitive Belastung, Umgebung\n\nDie Analysen wurden mit dem lavaan Package durchgeführt (Rosseel 2012).\nDie Gütekriterien des Messmodels sind in der Table 1 aufgeführt und weisen auf eine akzeptable Passung des Models hin (CFI=0.89 , GFI=0.91, RMSEA=0.06, SRMR=0.06). Der \\(\\chi^2\\)-Test (\\(\\chi^2\\)(179)=583.55, p &lt;0) fällt signifikant aus, was bei grossen Stichproben allerdings nicht ungewöhnlich ist, da diese direkt in die Teststatitsik miteinfliesst Eid, Gollwitzer, and Schmitt (2017).\n\n\n\n\n\n\n\n  \n    \n    \n      \n        χ²\n      \n      RMSEA\n      CFI\n      GFI\n      AGFI\n      SRMR\n    \n    \n      Wert\n      df\n      p\n    \n  \n  \n    583.553\n179\n0\n0.064\n0.892\n0.907\n0.88\n0.061\n  \n  \n  \n\nTable 1:  Gütekriterien des Messmodels \n\n\n\nFigure 1 zeigt die latenten Variablen des Messmodells mit den entsprechenden standardisierten Faktorladungen. Alle Ladungen erreichten ein signifikantes Resultat (p&lt;.001).\n\n\n\n\n\nFigure 1: Darstellung des Messmodells\n\n\n\n\nBetrachtet man die standardisierten Kovarianzen zwischen den latenten Faktoren des Modells (Figure 2) fällt besonders die zwischen den beiden Skalen KBE und KBU auf. Die Kovarianz beträgt 0.264 (SE=.036, z = 7,421, p &lt; .001). Die standardisierte Kovarianz war mit 0,940 bemerkenswert hoch und deutet auf eine starke lineare Beziehung zwischen diesen beiden Konstrukten hin. Alle Kovarianzen sind signifikant (p&lt;.01) ausser CANX~~PRA (p&lt;.085) und CANX~~IMO (p&lt;.795).\n\n\n\n\n\nFigure 2: Latente Faktoren und deren Kovarianzen im Messmodell\n\n\n\n\n\n\nIn den Modifikationsindices fällt besonders die hohe Kovarianz zwischen Items der Skala Intrinsische Motivation auf, was ein Hinweis auf Redundanz der Items sein könnte oder dass sie ein anderes Konstrukt messen.\nBesonders scheint das Items IMO_1 zu sein, da es als ein äusserst starker Indikator für die beiden Skalen KBE und KBU angesehen werden muss. Da diese Skalen völlig unterschiedliche Konstrukte messen, sticht diese Beziehung in besonderer Weise hervor.\n\n\n\n\n\n\n\n  \n    \n    \n      lhs\n      op\n      rhs\n      mi\n      epc\n      sepc.lv\n      sepc.all\n      sepc.nox\n    \n  \n  \n    IMO_3\n~~\nIMO_4\n94.95\n0.27\n0.27\n0.48\n0.48\n    KBE_2\n~~\nKBU_2\n86.40\n0.44\n0.44\n0.42\n0.42\n    IMO_1\n~~\nIMO_2\n46.23\n0.32\n0.32\n0.84\n0.84\n    KBU\n=~\nIMO_1\n34.87\n0.42\n0.23\n0.21\n0.21\n    KBE\n=~\nIMO_1\n32.14\n0.46\n0.23\n0.21\n0.21\n  \n  \n  \n\nTable 2:  Modifikationsindices, fünf höchste Werte \n\n\n\n\n\n\nDie Items der Skala lauten wie folgt:\n\nIch arbeite gerne mit dem Thema der Kuhhaltung. (IMO_1)\nEs macht Spass Aktivitäten rund um das Thema Kuhhaltung durchzuführen. (IMO_2)\nDas Thema der Kuhhaltung ist langweilig. (IMO_3)\nDas Thema der Kuhhaltung interessiert mich überhaupt nicht. (IMO_4)\nIch würde das Thema der Kuhhaltung als sehr interessant bezeichnen. (IMO_5)\n\nDa diese Items aus dem Englischen übersetzt und an unsere Situation adaptiert wurden, ist es sehr gut möglich, dass einzelne Items nicht ideal zum Konstrukt der intrinsischen Motivation passen. Item IMO_1 hat in dieser Hinsicht auch einen semantischen Fehler, da es nicht wirklich möglich ist mit einem Thema zu arbeiten."
  },
  {
    "objectID": "about.html#strukturmodell",
    "href": "about.html#strukturmodell",
    "title": "Statistische Analyse",
    "section": "Strukturmodell",
    "text": "Strukturmodell\n\n\n\n\n\n\n  \n    \n    \n      \n        χ²\n      \n      \n        RMSEA \n      \n      cfi\n      srmr\n    \n    \n      Wert\n      df\n      p\n      Wert\n      CIlow\n      CIhigh\n    \n  \n  \n    1,467.54\n243.00\n0.00\n0.10\n0.09\n0.10\n0.95\n0.09"
  },
  {
    "objectID": "about.html#cfa",
    "href": "about.html#cfa",
    "title": "Statistische Analyse",
    "section": "CFA",
    "text": "CFA\n\n\nlavaan 0.6.16 ended normally after 64 iterations\n\n  Estimator                                         ML\n  Optimization method                           NLMINB\n  Number of model parameters                        52\n\n  Number of observations                           554\n\nModel Test User Model:\n                                                      \n  Test statistic                               583.553\n  Degrees of freedom                               179\n  P-value (Chi-square)                           0.000\n\nModel Test Baseline Model:\n\n  Test statistic                              3957.559\n  Degrees of freedom                               210\n  P-value                                        0.000\n\nUser Model versus Baseline Model:\n\n  Comparative Fit Index (CFI)                    0.892\n  Tucker-Lewis Index (TLI)                       0.873\n\nLoglikelihood and Information Criteria:\n\n  Loglikelihood user model (H0)             -15629.004\n  Loglikelihood unrestricted model (H1)             NA\n                                                      \n  Akaike (AIC)                               31362.008\n  Bayesian (BIC)                             31586.500\n  Sample-size adjusted Bayesian (SABIC)      31421.429\n\nRoot Mean Square Error of Approximation:\n\n  RMSEA                                          0.064\n  90 Percent confidence interval - lower         0.058\n  90 Percent confidence interval - upper         0.070\n  P-value H_0: RMSEA &lt;= 0.050                    0.000\n  P-value H_0: RMSEA &gt;= 0.080                    0.000\n\nStandardized Root Mean Square Residual:\n\n  SRMR                                           0.061\n\nParameter Estimates:\n\n  Standard errors                             Standard\n  Information                                 Expected\n  Information saturated (h1) model          Structured\n\nLatent Variables:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  CANX =~                                                               \n    CANX_1            1.000                               0.382    0.209\n    CANX_2            2.940    0.645    4.557    0.000    1.122    0.644\n    CANX_3            3.526    0.760    4.642    0.000    1.345    0.815\n    CANX_4            3.488    0.751    4.645    0.000    1.331    0.900\n  PRA =~                                                                \n    PRA_1             1.000                               0.566    0.614\n    PRA_2             1.193    0.113   10.550    0.000    0.675    0.610\n    PRA_3             1.279    0.112   11.465    0.000    0.723    0.713\n    PRA_4             1.261    0.113   11.163    0.000    0.713    0.671\n  IMO =~                                                                \n    IMO_1             1.000                               0.910    0.814\n    IMO_2             0.822    0.048   17.104    0.000    0.748    0.790\n    IMO_3             0.586    0.043   13.598    0.000    0.533    0.610\n    IMO_4             0.651    0.050   13.008    0.000    0.592    0.584\n    IMO_5             0.551    0.057    9.623    0.000    0.501    0.438\n  KBE =~                                                                \n    KBE_1             1.000                               0.501    0.573\n    KBE_2             1.072    0.130    8.255    0.000    0.537    0.421\n    KBE_3             1.248    0.107   11.709    0.000    0.625    0.678\n    KBE_4             1.092    0.090   12.184    0.000    0.547    0.725\n  KBU =~                                                                \n    KBU_1             1.000                               0.558    0.736\n    KBU_2             1.057    0.090   11.735    0.000    0.589    0.540\n    KBU_3             1.084    0.074   14.606    0.000    0.605    0.674\n    KBU_4             1.105    0.068   16.296    0.000    0.616    0.758\n\nCovariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n  CANX ~~                                                               \n    PRA              -0.029    0.013   -2.207    0.027   -0.133   -0.133\n    IMO               0.004    0.017    0.252    0.801    0.013    0.013\n    KBE               0.051    0.015    3.326    0.001    0.267    0.267\n    KBU               0.064    0.018    3.603    0.000    0.301    0.301\n  PRA ~~                                                                \n    IMO               0.134    0.030    4.510    0.000    0.259    0.259\n    KBE              -0.117    0.020   -5.918    0.000   -0.413   -0.413\n    KBU              -0.113    0.020   -5.741    0.000   -0.359   -0.359\n  IMO ~~                                                                \n    KBE              -0.101    0.026   -3.852    0.000   -0.221   -0.221\n    KBU              -0.096    0.027   -3.527    0.000   -0.190   -0.190\n  KBE ~~                                                                \n    KBU               0.263    0.027    9.763    0.000    0.939    0.939\n\nVariances:\n                   Estimate  Std.Err  z-value  P(&gt;|z|)   Std.lv  Std.all\n   .CANX_1            3.184    0.193   16.535    0.000    3.184    0.956\n   .CANX_2            1.772    0.120   14.720    0.000    1.772    0.585\n   .CANX_3            0.917    0.095    9.705    0.000    0.917    0.336\n   .CANX_4            0.417    0.079    5.300    0.000    0.417    0.191\n   .PRA_1             0.530    0.039   13.433    0.000    0.530    0.623\n   .PRA_2             0.770    0.057   13.500    0.000    0.770    0.628\n   .PRA_3             0.507    0.046   11.105    0.000    0.507    0.492\n   .PRA_4             0.623    0.051   12.252    0.000    0.623    0.550\n   .IMO_1             0.422    0.044    9.619    0.000    0.422    0.338\n   .IMO_2             0.338    0.032   10.608    0.000    0.338    0.377\n   .IMO_3             0.480    0.033   14.627    0.000    0.480    0.628\n   .IMO_4             0.676    0.045   14.883    0.000    0.676    0.659\n   .IMO_5             1.057    0.067   15.849    0.000    1.057    0.808\n   .KBE_1             0.514    0.034   15.010    0.000    0.514    0.672\n   .KBE_2             1.338    0.084   15.941    0.000    1.338    0.822\n   .KBE_3             0.461    0.034   13.692    0.000    0.461    0.541\n   .KBE_4             0.271    0.021   12.666    0.000    0.271    0.475\n   .KBU_1             0.264    0.020   13.055    0.000    0.264    0.459\n   .KBU_2             0.843    0.055   15.426    0.000    0.843    0.708\n   .KBU_3             0.439    0.031   14.141    0.000    0.439    0.545\n   .KBU_4             0.281    0.022   12.508    0.000    0.281    0.425\n    CANX              0.146    0.062    2.329    0.020    1.000    1.000\n    PRA               0.320    0.046    6.924    0.000    1.000    1.000\n    IMO               0.827    0.079   10.449    0.000    1.000    1.000\n    KBE               0.251    0.037    6.765    0.000    1.000    1.000\n    KBU               0.311    0.033    9.386    0.000    1.000    1.000"
  },
  {
    "objectID": "about.html#efa",
    "href": "about.html#efa",
    "title": "Statistische Analyse",
    "section": "EFA",
    "text": "EFA"
  },
  {
    "objectID": "about.html#strukturmodell---nicht-betrachten--",
    "href": "about.html#strukturmodell---nicht-betrachten--",
    "title": "Statistische Analyse",
    "section": "Strukturmodell - Nicht betrachten ;-)",
    "text": "Strukturmodell - Nicht betrachten ;-)\n\n\n\n\n\n\n  \n    \n    \n      \n        χ²\n      \n      \n        RMSEA \n      \n      cfi\n      srmr\n    \n    \n      Wert\n      df\n      p\n      Wert\n      CIlow\n      CIhigh\n    \n  \n  \n    1,467.54\n243.00\n0.00\n0.10\n0.09\n0.10\n0.95\n0.09"
  },
  {
    "objectID": "about.html#modifikationsindices",
    "href": "about.html#modifikationsindices",
    "title": "Statistische Analyse",
    "section": "Modifikationsindices",
    "text": "Modifikationsindices\nDie Modifikationsindizes (vgl. Tabelle 3) deuten auf mögliche Querladungen zwischen der kognitiven Belastung in VR-Settings (KBU und KBE) und den Items der Skala zur intrinsischen Motivation (IMO_1 und IMO_3) hin. Dies könnte darauf hindeuten, dass bestimmte Items der Skala zur intrinsischen Motivation auch Aspekte der kognitiven Belastung erfassen oder dass es eine gewisse Überschneidung zwischen den Konstrukten gibt. Die vermutete inverse Beziehung zwischen PRA und CANX_1 könnte darauf hindeuten, dass mit zunehmender Präsenz in der VR-Umgebung der Wert von CANX_1 sinkt oder umgekehrt. Aufgrund des sehr guten Modell Fits sind allerdings keine Anpassungen am Modell vorzunehmen, allerdings stellt sich die Frage nach der internen Kongruenz oder Reliabilität der Item-Skalen, besonders der Motivationsskala.\n\n\nCode\nmodindices(model_fit1, minimum.value = 10, sort. = TRUE, maximum.number = 5) %&gt;% \n  gt() %&gt;% \n  fmt_number() %&gt;% \n  tab_style(locations = cells_column_labels(columns=c(2:7)),\n            style = cell_text(align = \"center\"))\n\n\n\n\n\n\n\n  \n    \n    \n      lhs\n      op\n      rhs\n      mi\n      epc\n      sepc.lv\n      sepc.all\n      sepc.nox\n    \n  \n  \n    PRA\n=~\nCANX_1\n85.97\n−0.36\n−0.27\n−0.27\n−0.27\n    KBE_2\n~~\nKBU_2\n85.35\n0.29\n0.29\n0.51\n0.51\n    KBU\n=~\nIMO_1\n75.59\n0.29\n0.24\n0.24\n0.24\n    KBE\n=~\nIMO_1\n72.80\n0.34\n0.24\n0.24\n0.24\n    IMO_1\n~~\nIMO_2\n64.82\n0.28\n0.28\n0.86\n0.86\n  \n  \n  \n\nTabelle 3:  Modifikationsindices, fünf höchste Werte \n\n\n\n\nKovarianzen der Items\nDie gefundenen Zusammenhänge der Items zeigen sich auch in der Kovarianzmatrix (Abbildung 3).\n\n\nCode\nlavResiduals(model_fit1)$cov %&gt;% \n  as.matrix() %&gt;% \n  corrplot(type = \"lower\", method = \"square\", tl.col = \"black\", tl.srt = 90, tl.offset = 0.4, tl.pos = \"ld\", tl.cex = .5, col.lim = c(-0.3,0.35), is.corr = FALSE)\n\n\nWarning in A/B: longer object length is not a multiple of shorter object length\n\n\n\n\n\nAbbildung 3: Korrelationsmatrix der Items\n\n\n\n\n\n\nItems der Skala Intrinsische Motivation\n\n\nCode\nomega(OLMA_Ready[,15:19], nfactors = 1)$schmid$sl %&gt;% \n  as.data.frame() %&gt;% \n  mutate(Item=rownames(omega(OLMA_Ready[,15:19], nfactors = 1)$schmid$sl)) %&gt;% \n  select(Item,dplyr::everything(), -\"F1*\", -\"p2\") %&gt;% \n  gt() %&gt;% \n  fmt_number() %&gt;% \n  tab_style(locations = cells_column_labels(columns=c(2:4)),\n            style = cell_text(align = \"center\"))\n\n\n\n\n\n\n\nTabelle 4:  Faktorladungen IMO-Skala \n  \n    \n    \n      Item\n      g\n      h2\n      u2\n    \n  \n  \n    IMO_1\n0.79\n0.63\n0.37\n    IMO_2\n0.75\n0.56\n0.44\n    IMO_3\n0.65\n0.42\n0.58\n    IMO_4\n0.63\n0.40\n0.60\n    IMO_5\n0.43\n0.18\n0.82\n  \n  \n  \n\n\n\n\nDie Items der Skala lauten wie folgt:\n\nIch arbeite gerne mit dem Thema der Kuhhaltung. (IMO_1)\nEs macht Spass Aktivitäten rund um das Thema Kuhhaltung durchzuführen. (IMO_2)\nDas Thema der Kuhhaltung ist langweilig. (IMO_3)\nDas Thema der Kuhhaltung interessiert mich überhaupt nicht. (IMO_4)\nIch würde das Thema der Kuhhaltung als sehr interessant bezeichnen. (IMO_5)\n\nDiese Items wurden aus dem Englischen übersetzt und an das Thema der Kuhhaltung angepasst. Die Formulierung von IMO_1 ist nicht ideal, da die Wendung “arbeiten mit einem Thema” nicht sehr geläufig ist und wahrscheinlich mit dem Verb “beschäftigen” besser getroffen worden wäre.\nEine Analyse der Itemskala mit der Omega Funktion des psych Packages (William Revelle 2023) durchgeführt und zeigen eine akzeptable interne Konsistenz der Skala mit \\(\\omega\\)=0.76 und \\(\\alpha\\)=0.74. Desweiteren zeigen auch die Faktorladungen, dass das Item 1 sowohl die höchste Ladung, als auch die höchste Komunalität mit dem latenten Faktor der Skala aufweist (siehe Tabelle 4). Diesen Analysen folgend macht eine Anpassung des Items IMO_1 keinen Sinn."
  },
  {
    "objectID": "about.html#items-der-skala-intrinsische-motivation",
    "href": "about.html#items-der-skala-intrinsische-motivation",
    "title": "Statistische Analyse",
    "section": "Items der Skala Intrinsische Motivation",
    "text": "Items der Skala Intrinsische Motivation\n\n\n\n\n\n\n\nTabelle 3:  Faktorladungen IMO-Skala \n  \n    \n    \n      Item\n      g\n      h2\n      u2\n    \n  \n  \n    IMO_1\n0.79\n0.63\n0.37\n    IMO_2\n0.75\n0.56\n0.44\n    IMO_3\n0.65\n0.42\n0.58\n    IMO_4\n0.63\n0.40\n0.60\n    IMO_5\n0.43\n0.18\n0.82\n  \n  \n  \n\n\n\n\nDie Items der Skala lauten wie folgt:\n\nIch arbeite gerne mit dem Thema der Kuhhaltung. (IMO_1)\nEs macht Spass Aktivitäten rund um das Thema Kuhhaltung durchzuführen. (IMO_2)\nDas Thema der Kuhhaltung ist langweilig. (IMO_3)\nDas Thema der Kuhhaltung interessiert mich überhaupt nicht. (IMO_4)\nIch würde das Thema der Kuhhaltung als sehr interessant bezeichnen. (IMO_5)\n\nDiese Items wurden aus dem Englischen übersetzt und an das Thema der Kuhhaltung angepasst. Die Formulierung von IMO_1 ist nicht ideal, da die Wendung “arbeiten mit einem Thema” nicht sehr geläufig ist und wahrscheinlich mit dem Verb “beschäftigen” besser getroffen worden wäre.\nEine Analyse der Itemskala mit der Omega Funktion des psych Packages (William Revelle 2023) durchgeführt und zeigen eine akzeptable interne Konsistenz der Skala mit \\(\\omega\\)=0.79 und \\(\\alpha\\)=0.78. Desweiteren zeigen auch die Faktorladungen, dass das Item 1 sowohl die höchste Ladung, als auch die höchste Komunalität mit dem latenten Faktor der Skala aufweist (siehe Tabelle 3). Diesen Analysen folgend macht eine Anpassung des Items IMO_1 keinen Sinn."
  },
  {
    "objectID": "about.html#angepasstes-messmodell",
    "href": "about.html#angepasstes-messmodell",
    "title": "Statistische Analyse",
    "section": "Angepasstes Messmodell",
    "text": "Angepasstes Messmodell"
  },
  {
    "objectID": "about.html#footnotes",
    "href": "about.html#footnotes",
    "title": "Statistische Analyse",
    "section": "Fußnoten",
    "text": "Fußnoten\n\n\nDiese CutOff Werte werden auch in Frage gestellt, da sie beeinflusst werden können von der Stichprobengrössen, Modellcharakteristika wie Non-Normalität, Anzahl der Indikatoren oder der Magnitude der Faktorladungen (West u. a. 2023). Eine mögliche Korrektur bietet Marcoulides und Yuan (2017). Das vorgestellte Modell bleibt auch hinsichtlich dieser Angaben ein guter Fit.↩︎"
  },
  {
    "objectID": "about.html#äquivalenztest",
    "href": "about.html#äquivalenztest",
    "title": "Statistische Analyse",
    "section": "Äquivalenztest",
    "text": "Äquivalenztest\nDiese CutOff Werte werden auch in Frage gestellt, da sie beeinflusst werden können von der Stichprobengrössen, Modellcharakteristika wie Non-Normalität, Anzahl der Indikatoren oder der Magnitude der Faktorladungen (West u. a. 2023). Eine mögliche Korrektur bieten Marcoulides und Yuan (2017) mit einem Äquivalenztest.\nDer korrigierte T-Size Wert für den CFI beträgt 0.945 und der RMSA 0.048. Verglichen mit den ebenfalls korrgierten T-Size korrigierten Cutoff-Werten (vgl. Tabelle 2) kann das Modell als “close” eingeschätzt werden.\n\n\nCode\ncalculate_cutoff(223, 554, 24) %&gt;% \n  rownames_to_column() %&gt;% \n  gt() %&gt;% \n  fmt_number(decimals = 3) %&gt;% \n  tab_style(locations = cells_column_labels(columns=everything()),\n            style = cell_text(align = \"center\"))\n\n\n\n\n\n\n\n  \n    \n    \n      \n      CFI\n      RMSEA\n    \n  \n  \n    mediocre\n0.880\n0.107\n    fair\n0.902\n0.086\n    close\n0.936\n0.056\n    excellent\n0.981\n0.021\n  \n  \n  \n\nTabelle 2:  Cut-Off Werte für den Äquivalenztest"
  },
  {
    "objectID": "about.html#latente-variablen-des-messmodells",
    "href": "about.html#latente-variablen-des-messmodells",
    "title": "Statistische Analyse",
    "section": "Latente Variablen des Messmodells",
    "text": "Latente Variablen des Messmodells\nAbbildung 1 zeigt die latenten Variablen des Messmodells mit den entsprechenden standardisierten Faktorladungen. Alle Ladungen erreichten ein signifikantes Resultat (p&lt;.001).\n\n\nCode\nsemPaths(model_fit1, \"std\", style = \"lisrel\", layout = \"tree2\", residuals = FALSE, layoutSplit = FALSE,sizeMan = 2, sizeLat = 6, rotation =2,exoCov = FALSE, intercepts = FALSE)\n\n\n\n\n\nAbbildung 1: Darstellung des Messmodells\n\n\n\n\nBetrachtet man die standardisierten Kovarianzen zwischen den latenten Faktoren des Modells (Abbildung 2) fällt besonders die zwischen den beiden Skalen KBE und KBU auf. Die Kovarianz beträgt 0.264 (SE=.036, z = 7,421, p &lt; .001). Die standardisierte Kovarianz war mit 0,940 bemerkenswert hoch und deutet auf eine starke lineare Beziehung zwischen diesen beiden Konstrukten hin. Alle Kovarianzen sind signifikant (p&lt;.01) ausser CANX~~PRA (p&lt;.085) und CANX~~IMO (p&lt;.795).\n\n\nCode\nsemPaths(model_fit1,\n         \"std\", \n         style = \"ram\", \n         layout = \"circle\", \n         residuals = FALSE, \n         layoutSplit = TRUE,\n         sizeMan = 0,\n         sizeLat2 = 8,\n         edge.label.cex = 1.5, \n         sizeLat = 10, \n         intercepts = FALSE,\n         nodeLabels = c(\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"\",\"CANX\", \"PRA\", \"IMO\", \"KBE\", \"KBU\", \"WIS\")\n)\n\n\n\n\n\nAbbildung 2: Latente Faktoren und deren Kovarianzen im Messmodell"
  },
  {
    "objectID": "about.html#modellparameter",
    "href": "about.html#modellparameter",
    "title": "Statistische Analyse",
    "section": "Modellparameter",
    "text": "Modellparameter\n\n\nCode\nsummary(model_fit2, standardized=TRUE)$pe %&gt;% \n  filter(op==\"~\") %&gt;%\n  gt() %&gt;% \n  fmt_number()\n\n\n\n\n\n\n  \n    \n    \n      lhs\n      op\n      rhs\n      exo\n      est\n      se\n      z\n      pvalue\n      std.lv\n      std.all\n      std.nox\n    \n  \n  \n    PRA\n~\nCANX\n0.00\n−0.58\n0.08\n−7.24\n0.00\n−0.36\n−0.36\n−0.36\n    IMO\n~\nPRA\n0.00\n0.44\n0.06\n7.38\n0.00\n0.37\n0.37\n0.37\n    KBE\n~\nPRA\n0.00\n−0.64\n0.05\n−11.63\n0.00\n−0.61\n−0.61\n−0.61\n    KBU\n~\nPRA\n0.00\n−0.67\n0.06\n−10.50\n0.00\n−0.55\n−0.55\n−0.55\n    WIS\n~\nIMO\n0.00\n0.30\n0.08\n3.49\n0.00\n0.32\n0.32\n0.32\n    WIS\n~\nKBE\n0.00\n2.36\n1.77\n1.33\n0.18\n2.23\n2.23\n2.23\n    WIS\n~\nKBU\n0.00\n−2.06\n1.52\n−1.36\n0.17\n−2.29\n−2.29\n−2.29\n    WIS\n~\nAlter\n1.00\n0.00\n0.00\n−1.61\n0.11\n−0.01\n−0.11\n−0.01"
  },
  {
    "objectID": "about.html#pfaddarstellung-des-sem-modells",
    "href": "about.html#pfaddarstellung-des-sem-modells",
    "title": "Statistische Analyse",
    "section": "Pfaddarstellung des SEM Modells",
    "text": "Pfaddarstellung des SEM Modells\n\n\nCode\nlavaanPlot2(model_fit2, \n            include = \"covs\",\n            graph_options = list(label = \"\"),\n            node_options = list( fontname = \"Helvetica\"), \n            edge_options = list(color = \"grey\"), \n            stars = c(\"latent\"), \n            coef_labels = TRUE)"
  }
]